import os
import glob
import cv2
import itertools
from natsort import natsorted
from backbones.iresnet import IResNet , IBasicBlock
import torch
import numpy as np
import matplotlib.pyplot as plt


def calculate_cosine_similarity_numpy(vec1, vec2):
    # GPU í…ì„œë¥¼ CPU numpyë¡œ ë³€í™˜
    if isinstance(vec1, torch.Tensor):
        vec1 = vec1.detach().cpu().numpy()
    if isinstance(vec2, torch.Tensor):
        vec2 = vec2.detach().cpu().numpy()

    vec1 = vec1.flatten()
    vec2 = vec2.flatten()
    
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    vec1_norm = vec1 / norm1
    vec2_norm = vec2 / norm2
    

    cosine_similarity = np.dot(vec1_norm, vec2_norm)
    

    if np.isfinite(cosine_similarity):
        return cosine_similarity
    else:
        return 0.0


representative_image = cv2.imread('frr_detected/0.jpg')
far_list = glob.glob('far_detected/*.jpg')  # ë‹¤ë¥¸ ì¸ë¬¼ (Negative samples)
frr_list = glob.glob('frr_detected/*.jpg')  # ê°™ì€ ì¸ë¬¼ (Positive samples)

far_list = natsorted(far_list)
frr_list = natsorted(frr_list)

print(f"FAR ì´ë¯¸ì§€ ìˆ˜: {len(far_list)} (ë‹¤ë¥¸ ì¸ë¬¼)")
print(f"FRR ì´ë¯¸ì§€ ìˆ˜: {len(frr_list)} (ê°™ì€ ì¸ë¬¼)")
print(f"ì´ í‰ê°€ ì´ë¯¸ì§€ ìˆ˜: {len(far_list) + len(frr_list)}")

Weight_path = 'Glint360K_R100_TopoFR_9760.pt'
backbone = IResNet(IBasicBlock, [3, 13, 30, 3] , num_classes=360232)
load_result = backbone.load_state_dict(torch.load(Weight_path, map_location='cpu'), strict=False)
backbone.eval()
backbone = backbone.to('cuda')
print("ëˆ„ë½ëœ ê°€ì¤‘ì¹˜ : {}".format(load_result.missing_keys))
print("ì˜ˆìƒì¹˜ëª»í•œ ê°€ì¤‘ì¹˜ : {}".format(load_result.unexpected_keys))

if not load_result.missing_keys and not load_result.unexpected_keys:
    print("ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

import torchvision.transforms.v2 as v2
from sklearn.metrics import roc_curve, auc, confusion_matrix

transforms_v2 = v2.Compose([
    v2.ToImage(), # cv2 HWC ---> Tensor C H W
    v2.ToDtype(torch.float32, scale=True),
    v2.CenterCrop(size=(112, 112)),
    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
])

# representative ì´ë¯¸ì§€ë„ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©
if representative_image.shape[0] != 112 or representative_image.shape[1] != 112:
    representative_image_resized = cv2.resize(representative_image, (112, 112), 
                                            interpolation=cv2.INTER_CUBIC if representative_image.shape[0] > 112 else cv2.INTER_AREA)
else:
    representative_image_resized = representative_image.copy()

# BGR â†’ RGB ë³€í™˜
representative_image_rgb = cv2.cvtColor(representative_image_resized, cv2.COLOR_BGR2RGB)

representative_image_tensor = transforms_v2(representative_image_rgb)  # âœ… RGB ìˆœì„œë¡œ ì²˜ë¦¬
representative_image_vector = representative_image_tensor.unsqueeze(0).to('cuda')
_ , representative_image_vector = backbone(representative_image_vector)

cv2.namedWindow('Representative Image', cv2.WINDOW_NORMAL)
cv2.namedWindow("compare_image",cv2.WINDOW_NORMAL)

# ëª¨ë“  ìœ ì‚¬ë„ì™€ ë¼ë²¨ ì €ì¥
all_similarities = []
all_labels = []

# 1. FRR ì´ë¯¸ì§€ë“¤ ì²˜ë¦¬ (ê°™ì€ ì¸ë¬¼ - Positive samples, label=1)
print("\n=== FRR ì´ë¯¸ì§€ ì²˜ë¦¬ (ê°™ì€ ì¸ë¬¼) ===")
for i, frr_img_path in enumerate(frr_list):
    if i == 0:  # representative ì´ë¯¸ì§€ëŠ” ì œì™¸
        continue
        
    image = cv2.imread(frr_img_path)
    
    # top_k_eval.pyì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©
    if image.shape[0] != 112 or image.shape[1] != 112:
        image = cv2.resize(image, (112, 112), 
                          interpolation=cv2.INTER_CUBIC if image.shape[0] > 112 else cv2.INTER_AREA)
    
    # BGR â†’ RGB ë³€í™˜
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # Transform ì ìš©
    image_tensor = transforms_v2(image_rgb)  # âœ… RGB ìˆœì„œë¡œ ì²˜ë¦¬
    image_tensor = image_tensor.unsqueeze(0).to('cuda')

    with torch.no_grad():
        output = backbone(image_tensor)
        if isinstance(output , tuple):
            _ , vectors  = output
        else:
            vectors = output

    cos_similarity = torch.nn.functional.cosine_similarity(representative_image_vector, vectors, dim=1)
    cos_similarity = cos_similarity.detach().cpu().numpy()[0]
    
    all_similarities.append(cos_similarity)
    all_labels.append(1)  # Positive sample
    
    print(f"FRR {i}: {frr_img_path} -> Similarity: {cos_similarity:.4f}")
    
# 2. FAR ì´ë¯¸ì§€ë“¤ ì²˜ë¦¬ (ë‹¤ë¥¸ ì¸ë¬¼ - Negative samples, label=0)
print("\n=== FAR ì´ë¯¸ì§€ ì²˜ë¦¬ (ë‹¤ë¥¸ ì¸ë¬¼) ===")
for i, far_img_path in enumerate(far_list):
    image = cv2.imread(far_img_path)
    
    # top_k_eval.pyì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©
    if image.shape[0] != 112 or image.shape[1] != 112:
        image = cv2.resize(image, (112, 112), 
                          interpolation=cv2.INTER_CUBIC if image.shape[0] > 112 else cv2.INTER_AREA)
    
    # BGR â†’ RGB ë³€í™˜
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # Transform ì ìš©
    image_tensor = transforms_v2(image_rgb)  # âœ… RGB ìˆœì„œë¡œ ì²˜ë¦¬
    image_tensor = image_tensor.unsqueeze(0).to('cuda')

    with torch.no_grad():
        output = backbone(image_tensor)
        if isinstance(output , tuple):
            _ , vectors  = output
        else:
            vectors = output

    cos_similarity = torch.nn.functional.cosine_similarity(representative_image_vector, vectors, dim=1)
    cos_similarity = cos_similarity.detach().cpu().numpy()[0]
    
    all_similarities.append(cos_similarity)
    all_labels.append(0)  # Negative sample
    
    print(f"FAR {i}: {far_img_path} -> Similarity: {cos_similarity:.4f}")

cv2.destroyAllWindows()

# 3. ì„±ëŠ¥ í‰ê°€ ìˆ˜í–‰
print("\n=== ì„±ëŠ¥ í‰ê°€ ===")
similarities_np = np.array(all_similarities)
labels_np = np.array(all_labels)

print(f"ì´ í‰ê°€ ìŒ: {len(similarities_np)}ê°œ")
print(f"Positive ìŒ (ê°™ì€ ì¸ë¬¼): {np.sum(labels_np)}ê°œ")
print(f"Negative ìŒ (ë‹¤ë¥¸ ì¸ë¬¼): {np.sum(labels_np == 0)}ê°œ")

if len(similarities_np) > 0:
    # ROC ì»¤ë¸Œ ê³„ì‚°
    fpr, tpr, thresholds = roc_curve(labels_np, similarities_np)
    roc_auc = auc(fpr, tpr)
    
    # EER ê³„ì‚°
    frr = 1 - tpr  # FRR = 1 - TPR
    eer_index = np.nanargmin(np.abs(fpr - frr))
    eer = fpr[eer_index]
    eer_threshold = thresholds[eer_index]
    
    # EER ì„ê³„ì ìœ¼ë¡œ ë¶„ë¥˜
    predictions = (similarities_np >= eer_threshold).astype(int)
    cm = confusion_matrix(labels_np, predictions)
    
    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    # FARê³¼ FRR ê³„ì‚°
    far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Accept Rate
    frr_rate = fn / (fn + tp) if (fn + tp) > 0 else 0  # False Reject Rate
    
    print("\n--- ğŸ“Š ìµœì¢… ì„±ëŠ¥ ê²°ê³¼ ---")
    print(f"ğŸ¯ ROC-AUC: {roc_auc:.4f}")
    print(f"ğŸ¯ EER: {eer:.4f} (ì„ê³„ê°’: {eer_threshold:.4f})")
    print(f"ğŸ“ˆ Accuracy: {accuracy:.4f}")
    print(f"ğŸ“ˆ Precision: {precision:.4f}")
    print(f"ğŸ“ˆ Recall (TPR): {recall:.4f}")
    print(f"ğŸ“ˆ Specificity (TNR): {specificity:.4f}")
    print(f"ğŸ“ˆ F1-Score: {f1_score:.4f}")
    print(f"ğŸ“ˆ FAR (False Accept Rate): {far:.4f}")
    print(f"ğŸ“ˆ FRR (False Reject Rate): {frr_rate:.4f}")
    
    print("\n--- ğŸ”¢ Confusion Matrix ---")
    print(f"True Positive (TP): {tp} (ê°™ì€ ì¸ë¬¼ì„ ê°™ì€ ì¸ë¬¼ë¡œ ì¸ì‹)")
    print(f"True Negative (TN): {tn} (ë‹¤ë¥¸ ì¸ë¬¼ì„ ë‹¤ë¥¸ ì¸ë¬¼ë¡œ ì¸ì‹)")
    print(f"False Positive (FP): {fp} (ë‹¤ë¥¸ ì¸ë¬¼ì„ ê°™ì€ ì¸ë¬¼ë¡œ ì˜¤ì¸ì‹)")
    print(f"False Negative (FN): {fn} (ê°™ì€ ì¸ë¬¼ì„ ë‹¤ë¥¸ ì¸ë¬¼ë¡œ ì˜¤ì¸ì‹)")

    # --- Enhanced Statistics ---
    p10 = np.percentile(similarities_np, 10)
    p50 = np.median(similarities_np) # Median
    p90 = np.percentile(similarities_np, 90)

    print("\n--- ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„ ---")
    print(f"ğŸ”´ ìœ ì‚¬ë„ (ì´ {len(similarities_np):,}ê°œ):")
    print(f"   - ìµœì†Œê°’: {np.min(similarities_np):.4f}")
    print(f"   - 10% ë¶„ìœ„: {p10:.4f}")
    print(f"   - ì¤‘ì•™ê°’ (Median): {p50:.4f}")
    print(f"   - 90% ë¶„ìœ„: {p90:.4f}")
    print(f"   - ìµœëŒ€ê°’: {np.max(similarities_np):.4f}")
    print(f"   - í‰ê· ê°’: {np.mean(similarities_np):.4f}")
    print(f"   - í‘œì¤€í¸ì°¨: {np.std(similarities_np):.4f}")

    # --- ROC Curve Visualization ---
    plt.figure(figsize=(15, 5))
    
    # 1. ROC ì»¤ë¸Œ
    plt.subplot(1, 3, 1)
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.scatter(fpr[eer_index], tpr[eer_index], color='red', s=100, zorder=5, label=f'EER = {eer:.4f}')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate (FAR)')
    plt.ylabel('True Positive Rate (TPR)')
    plt.title('ROC Curve')
    plt.legend(loc="lower right")
    plt.grid(True)
    
    # 2. ìœ ì‚¬ë„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
    plt.subplot(1, 3, 2)
    positive_similarities = similarities_np[labels_np == 1]
    negative_similarities = similarities_np[labels_np == 0]
    
    plt.hist(positive_similarities, bins=30, alpha=0.7, color='green', label=f'Same Person (n={len(positive_similarities)})', density=True)
    plt.hist(negative_similarities, bins=30, alpha=0.7, color='red', label=f'Different Person (n={len(negative_similarities)})', density=True)
    plt.axvline(eer_threshold, color='black', linestyle='--', linewidth=2, label=f'EER Threshold: {eer_threshold:.3f}')
    plt.xlabel('Cosine Similarity')
    plt.ylabel('Density')
    plt.title('Similarity Distribution')
    plt.legend()
    plt.grid(True)
    
    # 3. Confusion Matrix íˆíŠ¸ë§µ
    plt.subplot(1, 3, 3)
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    im = plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Normalized Confusion Matrix')
    plt.colorbar(im)
    
    classes = ['Different Person', 'Same Person']
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    
    # í…ìŠ¤íŠ¸ ì¶”ê°€
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, f'{cm[i, j]}\n({cm_normalized[i, j]:.2%})',
                ha="center", va="center", color="white" if cm_normalized[i, j] > 0.5 else "black")
    
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()

    plot_filename = "face_recognition_evaluation.png"
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    print(f"\nğŸ“Š í‰ê°€ ê²°ê³¼ ê·¸ë˜í”„ê°€ '{plot_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    plt.show()

else:
    print("âš ï¸ í‰ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
