import os
import itertools
import random
import numpy as np
import pandas as pd
import torch
import cv2
from tqdm import tqdm
from sklearn.metrics import roc_curve, auc, confusion_matrix
import logging
import traceback
import pickle
import argparse
import matplotlib.pyplot as plt
import logging
import torchvision.transforms.v2 as v2
from PIL import Image
import numpy as np
from backbones.iresnet import IResNet , IBasicBlock
from multiprocessing.pool import Pool
from datetime import datetime

try:
    script_dir = os.path.dirname(os.path.abspath(__file__))
except NameError:
    script_dir = os.getcwd()


def init_worker(worker_embeddings):
    """ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì´ˆê¸°í™” í•¨ìˆ˜. embeddings ë”•ì…”ë„ˆë¦¬ë¥¼ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."""
    global embeddings
    embeddings = worker_embeddings

transforms_v2 = v2.Compose([
    v2.ToImage(), # cv2 HWC ---> Tensor C H W
    v2.ToDtype(torch.float32, scale=True),
    v2.CenterCrop(size=(112, 112)),
    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
])

@torch.inference_mode()
def get_all_embeddings(identity_map, backbone, device, batch_size):

    logging.info(f"ì„ë² ë”© ì¶”ì¶œ ë°°ì¹˜ì‚¬ì´ì¦ˆ : {batch_size}")

    if isinstance(device, str):
        device = torch.device(device)
    
    backbone = backbone.to(device)
    backbone.eval()
    embeddings = {} # {ì´ë¯¸ì§€ê²½ë¡œ : ì´ë¯¸ì§€ë²¡í„°}
    all_images = sorted(list(set(itertools.chain.from_iterable(identity_map.values())))) #ëª¨ë“ ì´ë¯¸ì§€ê²½ë¡œ í‰íƒ„í™”
     
    def preprocess_image(image):
        transformed_image = transforms_v2(image)
        return transformed_image

    for i in tqdm(range(0, len(all_images), batch_size), desc='ì„ë² ë”© ì¶”ì¶œ'):
        batch_paths = all_images[i:i+batch_size] # ë°°ì¹˜ë‹¨ìœ„ë¡œ ê²½ë¡œ ì¶”ì¶œ
        batch_images = []
        valid_paths = []

        for img_path in batch_paths: # ë°°ì¹˜ë‹¨ìœ„ë¡œ í•˜ë‚˜ì”© -> tensorê°’ìœ¼ë¡œ ë³€í™˜
            try:
                image = cv2.imread(img_path)
                if image is None:
                    logging.warning(f"{img_path} ê²½ë¡œ ì´ë¯¸ì§€ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤")
                    embeddings[img_path] = None
                    continue

                if image.shape[0] != 112 or image.shape[1] != 112:
                    image = cv2.resize(image, (112, 112), interpolation=cv2.INTER_CUBIC if image.shape[0] > 112 else cv2.INTER_AREA)
                
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                processed_image = preprocess_image(image_rgb)
                batch_images.append(processed_image)
                valid_paths.append(img_path)

            except Exception as e:
                logging.warning(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ê²½ë¡œ : {img_path} ì˜¤ë¥˜ : {e}")
                embeddings[img_path] = None
        
        if not batch_images:
            continue

        batch_tensor = torch.stack(batch_images).to(device) # ë°°ì¹˜ë‹¨ìœ„ë¡œ í•˜ë‚˜ë¡œë§Œë“¤ì–´

        try:
            with torch.amp.autocast(device_type=device.type, dtype=torch.float16):
                
                output = backbone(batch_tensor)
                if isinstance(output , tuple):
                    _ , vectors  = output

                else:
                    vectors = output
        

            if vectors is None or vectors.numel() == 0:
                logging.warning(f"ë²¡í„° ì¶”ì¶œ ì‹¤íŒ¨ (ë°°ì¹˜ í¬ê¸°: {len(batch_paths)})")
                for path in valid_paths:
                    embeddings[path] = None

            else:
                vectors_cpu = vectors.cpu().numpy()
                for path, vector in zip(valid_paths, vectors_cpu):
                    embeddings[path] = vector.flatten()

        except Exception as e:
            logging.warning(f"ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨ (ë°°ì¹˜ í¬ê¸°: {len(batch_paths)}) ì˜¤ë¥˜ : {e}")
            for path in valid_paths:
                embeddings[path] = None
    try:
        sp = args.data_path
        sp = sp.split('/')[-1]
        file_name = f'{args.model}.npz'
        np.savez_compressed(f'{file_name}' , **embeddings)
        logging.info(f"ì„ë² ë”© ìºì‹œ ì €ì¥ì™„ë£Œ íŒŒì¼ì´ë¦„ : {file_name}")

    except Exception as e:
        logging.info(f'{e}')
        logging.info("@@ì„ë² ë”© ìºì‹œ ì €ì¥ ì‹¤íŒ¨ ì½”ë“œê²€ìˆ˜.....!!@@")

    return embeddings

def collect_scores_from_embeddings(pairs, embeddings, is_positive, total_pairs=None):
    """ì„ë² ë”©ìœ¼ë¡œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©)."""
    similarities, labels = [], []
    label = 1 if is_positive else 0
    desc = "ë™ì¼ ì¸ë¬¼ ìŒ ê³„ì‚°" if is_positive else "ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ê³„ì‚°"

    if total_pairs is None:
        try:
            total_pairs = len(pairs)
        except TypeError:
            total_pairs = None 

    for img1_path, img2_path in tqdm(pairs, desc=desc, total=total_pairs):
        emb1, emb2 = embeddings.get(img1_path), embeddings.get(img2_path)
        if emb1 is not None and emb2 is not None:
        
            norm1 = np.linalg.norm(emb1)
            norm2 = np.linalg.norm(emb2)
            
            if norm1 == 0 or norm2 == 0:
                logging.warning(f"Zero norm embedding found: {img1_path} or {img2_path}")
                continue
            
            emb1_norm = emb1 / norm1
            emb2_norm = emb2 / norm2
            cosine_similarity = np.dot(emb1_norm, emb2_norm)
            
            if np.isfinite(cosine_similarity):
                similarities.append(cosine_similarity)
                labels.append(label)
            else:
                logging.warning(f"Invalid similarity computed: {cosine_similarity}")
    
    return similarities, labels

def _calculate_similarity_for_pair(pair):
    """í•œ ìŒì˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ìš©)"""
    # init_workerì— ì˜í•´ ì„¤ì •ëœ ì „ì—­ ë³€ìˆ˜ embeddingsë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    global embeddings
    img1_path, img2_path = pair
    
    emb1 = embeddings.get(img1_path)
    emb2 = embeddings.get(img2_path)
    
    if emb1 is not None and emb2 is not None:
        norm1 = np.linalg.norm(emb1)
        norm2 = np.linalg.norm(emb2)
        if norm1 > 0 and norm2 > 0:
            # ì •ê·œí™”ì™€ ë‚´ì ì„ í•œ ë²ˆì— ê³„ì‚°
            cosine_similarity = np.dot(emb1, emb2) / (norm1 * norm2)
            if np.isfinite(cosine_similarity):
                return cosine_similarity
    return None # ê³„ì‚° ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

def calculate_identification_metrics(identity_map, embeddings ):
    logging.info("Calculating identification metrics (Rank-k, CMC)...")

    gallery_images = {} # {identity: image_path}
    probe_images_with_labels = [] # [(image_path, identity)]

    # Split data into gallery and probe sets
    # For each identity, take one image for gallery, rest for probes
    for identity, img_paths in identity_map.items():
        if not img_paths:
            continue
        
        # Use the first image as gallery representative
        try:
            gallery_images[identity] = img_paths[2098]
            idx = 2098 
        except:
            logging.info("ëŒ€í‘œì´ë¯¸ì§€ 0ìœ¼ë¡œ ì„¤ì •í•¨ top k ë¶€ì •í™•")
            gallery_images[identity] = img_paths[0]
            idx = 0

        for i in range(0, len(img_paths)):
            if i == idx:
                continue
            probe_images_with_labels.append((img_paths[i], identity))  # ì´ë¯¸ì§€ì™€ í•´ë‹¹ì‚¬ëŒ í´ë˜ìŠ¤
    
    
    if not probe_images_with_labels:
        logging.warning("No probe images available for identification evaluation. Skipping identification metrics.")
        return None, None, None, None, None

    logging.info(f"Identities in gallery: {len(gallery_images)}")
    logging.info(f"Total probe images: {len(probe_images_with_labels)}")

    # Prepare gallery embeddings
    gallery_embeddings = [] # list of (embedding, identity)
    gallery_identities_ordered = [] # ordered list of identities corresponding to gallery_embeddings
    for identity in sorted(gallery_images.keys()): # Sort to ensure consistent order
        img_path = gallery_images[identity]
        emb = embeddings.get(img_path) # ëŒ€í‘œì´ë¯¸ì§€ ì„ë² ë”©ê°’ ì¶”ì¶œ
        if emb is not None:
            gallery_embeddings.append(emb / np.linalg.norm(emb)) # Normalize
            gallery_identities_ordered.append(identity)
        else:
            logging.warning(f"Gallery image embedding missing for identity {identity}: {img_path}")
    
    if not gallery_embeddings:
        logging.error("No valid gallery embeddings found. Cannot perform identification evaluation.")
        return None, None, None, None, None

    gallery_embeddings_np = np.array(gallery_embeddings)

    # Max rank for CMC curve
    max_rank = len(gallery_identities_ordered) # Max possible rank is number of identities in gallery
    if max_rank == 0: # Avoid division by zero if no gallery
        logging.error("Gallery is empty. Cannot calculate identification metrics.")
        return None, None, None, None, None
    
    cmc_hits = np.zeros(max_rank, dtype=int)
    total_probes = 0

    rank_1_correct = 0
    rank_5_correct = 0
    
    for probe_img_path, true_identity in tqdm(probe_images_with_labels, desc="Evaluating identification"):
        probe_emb = embeddings.get(probe_img_path) # ì¶”ì¸¡ ì„ë² ë”© ì¶”ì¶œ
        if probe_emb is None:
            logging.warning(f"Probe image embedding missing: {probe_img_path}. Skipping.")
            continue
        
        probe_emb_norm = probe_emb / np.linalg.norm(probe_emb)

        # Calculate similarities with all gallery embeddings
        similarities = np.dot(gallery_embeddings_np, probe_emb_norm)# (class , 512 )  dot (512 ,)= (class, 1) -> ì—ì¸¡ì´ë¯¸ì§€ì—ëŒ€í•˜ì—¬ ëŒ€í‘œì´ë¯¸ì§€ ì „ë¶€ ìœ ì‚¬í•œì •ë„ êµ¬í•˜ê¸° 
        
        # Get ranks (indices of sorted similarities in descending order)
        # argsort returns indices that would sort an array in ascending order.
        # To get descending, we can negate the similarities and then argsort.
        ranked_indices = np.argsort(similarities)[::-1] 
        
        # Find the rank of the true identity
        true_identity_rank = -1
        for rank, idx in enumerate(ranked_indices):
            if gallery_identities_ordered[idx] == true_identity:
                true_identity_rank = rank + 1 # Rank is 1-based
                break
        
        if true_identity_rank != -1:
            # Update CMC hits
            for r in range(true_identity_rank, max_rank + 1):
                cmc_hits[r-1] += 1 # cmc_hits is 0-indexed
            
            # Update Rank-1 and Rank-5
            if true_identity_rank == 1:
                rank_1_correct += 1
            if true_identity_rank <= 5:
                rank_5_correct += 1
        
        total_probes += 1

    if total_probes == 0:
        logging.warning("No valid probes processed for identification evaluation.")
        return None, None, None, None, None

    rank_1_accuracy = rank_1_correct / total_probes
    rank_5_accuracy = rank_5_correct / total_probes
    
    cmc_curve = cmc_hits / total_probes

    logging.info(f"Rank-1 Accuracy: {rank_1_accuracy:.4f}")
    logging.info(f"Rank-5 Accuracy: {rank_5_accuracy:.4f}")
    logging.info(f"CMC Curve calculated up to rank {max_rank}")

    return rank_1_accuracy, rank_5_accuracy, cmc_curve, max_rank, total_probes

def main(args):
    LOG_FILE = os.path.join(script_dir , f'{args.model}_LOG.log')
    torch.backends.cudnn.benchmark = True
    np.random.seed(42)
    random.seed(42)
    logging.basicConfig(
        filename=LOG_FILE, level=logging.WARNING,
        format='%(asctime)s - %(levelname)s - %(message)s', filemode='w'
    )
    
    if not os.path.isdir(args.data_path):
        raise FileNotFoundError(f"ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.data_path}")

    if args.model =='Glint360K_R200_TopoFR':
        Weight_path = 'Glint360K_R200_TopoFR_9784.pt'
        backbone = IResNet(IBasicBlock, [6, 26, 60, 6] , num_classes=360232)

    elif args.model == 'MS1MV2_R200_TopoFR':
        Weight_path = 'MS1MV2_R200_TopoFR_9712_cosface.pt'
        backbone = IResNet(IBasicBlock, [6, 26, 60, 6] , num_classes=85742)

    elif args.model == 'Glint360K_R100_TopoFR_9760':
        Weight_path = 'Glint360K_R100_TopoFR_9760.pt'
        backbone = IResNet(IBasicBlock, [3, 13, 30, 3] , num_classes=360232)

    elif args.model == 'Glint360K_R50_TopoFR_9727':
        Weight_path = 'Glint360K_R50_TopoFR_9727.pt'
        backbone = IResNet(IBasicBlock , [3,4,14,3] , num_classes= 360232)

    else:
        logging.info(f"Select Model {args.model}")
        exit(0)



    load_result = backbone.load_state_dict(torch.load(Weight_path, map_location='cpu'), strict=False)
    print("ëˆ„ë½ëœ ê°€ì¤‘ì¹˜ : {}".format(load_result.missing_keys))
    print("ì˜ˆìƒì¹˜ëª»í•œ ê°€ì¤‘ì¹˜ : {}".format(load_result.unexpected_keys))

    if not load_result.missing_keys and not load_result.unexpected_keys:
        print("ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    flag = str(input("ì§„í–‰ì‹œ ì•„ë¬´í‚¤... (1)ì¢…ë£Œ..."))
    if flag == '1':
        logging.info("ì¢…ë£Œ../")
        exit(0)

    backbone = torch.compile(backbone)

    identity_map = {} # ì‚¬ëŒí´ë”ë¼ë²¨ : í•´ë‹¹ í´ë” ì‚¬ëŒ ì´ë¯¸ì§€ ê²½ë¡œ
    for person_folder in sorted(os.listdir(args.data_path)):
        person_path = os.path.join(args.data_path, person_folder) # ê° ì‚¬ëŒí´ë”ì˜ ê²½ë¡œ
        if os.path.isdir(person_path):
            images = [os.path.join(person_path, f) for f in os.listdir(person_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))] # ê°ì‚¬ëŒí´ë”ì— ë“¤ì–´ìˆëŠ” ëª¨ë“  jpg
            if len(images) > 1:
                identity_map[person_folder] = images
    
    if not identity_map:
        raise ValueError("ë°ì´í„°ì…‹ì—ì„œ 2ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ê°€ì§„ ì¸ë¬¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    print(f"ì´ {len(identity_map)}ëª…ì˜ ì¸ë¬¼, {sum(len(v) for v in identity_map.values())}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    print("\ní‰ê°€ì— ì‚¬ìš©í•  ë™ì¼ ì¸ë¬¼/ë‹¤ë¥¸ ì¸ë¬¼ ìŒì„ ìƒì„±í•©ë‹ˆë‹¤...")
    
    positive_pairs = []
    for imgs in tqdm(identity_map.values(), desc="ë™ì¼ ì¸ë¬¼ ìŒ ìƒì„±"):
        positive_pairs.extend(itertools.combinations(imgs, 2))

    num_positive_pairs = len(positive_pairs)


    identities = list(identity_map.keys())
    negative_pairs_set = set()
    if len(identities) > 1:
        with tqdm(total=num_positive_pairs, desc="ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ìƒì„±") as pbar:
            while len(negative_pairs_set) < num_positive_pairs:
                id1, id2 = random.sample(identities, 2)
                pair = (random.choice(identity_map[id1]), random.choice(identity_map[id2]))
                sorted_pair = tuple(sorted(pair))
                if sorted_pair not in negative_pairs_set:
                    negative_pairs_set.add(sorted_pair)
                    pbar.update(1)
    negative_pairs = list(negative_pairs_set)

    print(f"- ë™ì¼ ì¸ë¬¼ ìŒ: {len(positive_pairs)}ê°œ, ë‹¤ë¥¸ ì¸ë¬¼ ìŒ: {len(negative_pairs)}ê°œ")


    if args.load_cache is not None :
        cache_path = args.load_cache
        loaded_npz = np.load(cache_path)
        embeddings = {key: loaded_npz[key] for key in tqdm(loaded_npz.files , desc='ì„ë² ë”© ìºì‹œ ë¡œë”©..')}
        embeddings = loaded_npz

    else:
        embeddings = get_all_embeddings(
            identity_map, backbone, args.device,args.batch_size
        )

    with Pool(initializer=init_worker, initargs=(embeddings,)) as pool:
        # 1. ë™ì¼ ì¸ë¬¼ ìŒ ê³„ì‚°
        pos_results = list(tqdm(pool.imap_unordered(_calculate_similarity_for_pair, positive_pairs , chunksize= 1000), 
                                total=len(positive_pairs), 
                                desc="ë™ì¼ ì¸ë¬¼ ìŒ ê³„ì‚°"))
        pos_similarities = [r for r in pos_results if r is not None]
        pos_labels = [1] * len(pos_similarities)

        # 2. ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ê³„ì‚°
        neg_results = list(tqdm(pool.imap_unordered(_calculate_similarity_for_pair, negative_pairs , chunksize = 1000), 
                                total=len(negative_pairs), 
                                desc="ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ê³„ì‚°"))
        neg_similarities = [r for r in neg_results if r is not None]
        neg_labels = [0] * len(neg_similarities)

    print(f"ğŸ” ë””ë²„ê¹… ì •ë³´:")
    print(f"   - ì „ì²´ ì„ë² ë”© ìˆ˜: {len(embeddings)}")
    print(f"   - ìœ íš¨í•œ ì„ë² ë”© ìˆ˜: {sum(1 for v in embeddings.values() if v is not None)}")
    print(f"   - None ì„ë² ë”© ìˆ˜: {sum(1 for v in embeddings.values() if v is None)}")
    print(f"   - ì–‘ì„± ìŒ ìœ ì‚¬ë„ ìˆ˜ (ë³€í™˜ ì „): {len(pos_similarities)}")
    print(f"   - ìŒì„± ìŒ ìœ ì‚¬ë„ ìˆ˜ (ë³€í™˜ ì „): {len(neg_similarities)}")
    
    pos_similarities_array = np.array(pos_similarities)
    neg_similarities_array = np.array(neg_similarities)
    
    print(f"   - NaN ê°œìˆ˜ (ì–‘ì„±/ìŒì„±): {np.isnan(pos_similarities_array).sum()} / {np.isnan(neg_similarities_array).sum()}")
    print(f"   - Inf ê°œìˆ˜ (ì–‘ì„±/ìŒì„±): {np.isinf(pos_similarities_array).sum()} / {np.isinf(neg_similarities_array).sum()}")

    pos_similarities = pos_similarities_array
    neg_similarities = neg_similarities_array
    pos_labels = np.array(pos_labels)
    neg_labels = np.array(neg_labels)

    pos_finite_mask = np.isfinite(pos_similarities)
    neg_finite_mask = np.isfinite(neg_similarities)

    pos_similarities = pos_similarities[pos_finite_mask]
    neg_similarities = neg_similarities[neg_finite_mask]
    pos_labels = pos_labels[pos_finite_mask]
    neg_labels = neg_labels[neg_finite_mask]


    with open(LOG_FILE, 'a') as log_file:
        log_file.write(f"í˜„ì¬ì‹œê° : {datetime.now().strftime('%Y.%m.%d - %H:%M:%S')}\n")
        log_file.write(f"\nğŸ” ë””ë²„ê¹… ì •ë³´:\n")
        log_file.write(f"   - ì „ì²´ ì„ë² ë”© ìˆ˜: {len(embeddings)}\n")
        log_file.write(f"   - ìœ íš¨í•œ ì„ë² ë”© ìˆ˜: {sum(1 for v in embeddings.values() if v is not None)}\n")
        log_file.write(f"   - None ì„ë² ë”© ìˆ˜: {sum(1 for v in embeddings.values() if v is None)}\n")
        log_file.write(f"   - ì–‘ì„± ìŒ ìœ ì‚¬ë„ ìˆ˜ (í•„í„°ë§ í›„): {len(pos_similarities)}\n")
        log_file.write(f"   - ìŒì„± ìŒ ìœ ì‚¬ë„ ìˆ˜ (í•„í„°ë§ í›„): {len(neg_similarities)}\n")

    print(f"\n--- ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„ ---")
    if len(pos_similarities) > 0 and len(neg_similarities) > 0:
        def safe_std(arr):
            try:
                arr_f64 = arr.astype(np.float64)
                std_val = np.std(arr_f64, dtype=np.float64)
                return std_val if np.isfinite(std_val) else "overflow"
            except:
                return "ê³„ì‚° ë¶ˆê°€"
        
        pos_std = safe_std(pos_similarities)
        neg_std = safe_std(neg_similarities)
        
        print(f"ğŸ”µ ë™ì¼ ì¸ë¬¼ ìŒ ìœ ì‚¬ë„ (ì´ {len(pos_similarities):,}ê°œ):")
        print(f"   - ìµœì†Œê°’: {np.min(pos_similarities):.4f}")
        print(f"   - ìµœëŒ€ê°’: {np.max(pos_similarities):.4f}")
        print(f"   - í‰ê· ê°’: {np.mean(pos_similarities.astype(np.float64)):.4f}")
        print(f"   - í‘œì¤€í¸ì°¨: {pos_std:.4f}" if isinstance(pos_std, (int, float)) else f"   - í‘œì¤€í¸ì°¨: {pos_std}")
        
        print(f"ğŸ”´ ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ìœ ì‚¬ë„ (ì´ {len(neg_similarities):,}ê°œ):")
        print(f"   - ìµœì†Œê°’: {np.min(neg_similarities):.4f}")
        print(f"   - ìµœëŒ€ê°’: {np.max(neg_similarities):.4f}")
        print(f"   - í‰ê· ê°’: {np.mean(neg_similarities.astype(np.float64)):.4f}")
        print(f"   - í‘œì¤€í¸ì°¨: {neg_std:.4f}" if isinstance(neg_std, (int, float)) else f"   - í‘œì¤€í¸ì°¨: {neg_std}")


        with open(LOG_FILE, 'a') as log_file:
            log_file.write(f"\n--- ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„ ---\n")
            log_file.write(f"ğŸ”µ ë™ì¼ ì¸ë¬¼ ìŒ ìœ ì‚¬ë„ (ì´ {len(pos_similarities):,}ê°œ):\n")
            log_file.write(f"   - ìµœì†Œê°’: {np.min(pos_similarities):.4f}\n")
            log_file.write(f"   - ìµœëŒ€ê°’: {np.max(pos_similarities):.4f}\n")
            log_file.write(f"   - í‰ê· ê°’: {np.mean(pos_similarities.astype(np.float64)):.4f}\n")
            log_file.write(f"   - í‘œì¤€í¸ì°¨: {pos_std:.4f}\n" if isinstance(pos_std, (int, float)) else f"   - í‘œì¤€í¸ì°¨: {pos_std}\n")
            
            log_file.write(f"ğŸ”´ ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ìœ ì‚¬ë„ (ì´ {len(neg_similarities):,}ê°œ):\n")
            log_file.write(f"   - ìµœì†Œê°’: {np.min(neg_similarities):.4f}\n")
            log_file.write(f"   - ìµœëŒ€ê°’: {np.max(neg_similarities):.4f}\n")
            log_file.write(f"   - í‰ê· ê°’: {np.mean(neg_similarities.astype(np.float64)):.4f}\n")
            log_file.write(f"   - í‘œì¤€í¸ì°¨: {neg_std:.4f}\n" if isinstance(neg_std, (int, float)) else f"   - í‘œì¤€í¸ì°¨: {neg_std}\n")
    else:
        print("ìœ ì‚¬ë„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ë¶„í¬ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"len pos : {len(pos_similarities)}, len neg: {len(neg_similarities)}")
        exit(0)
    
    scores = np.concatenate([pos_similarities, neg_similarities])
    labels = np.concatenate([pos_labels, neg_labels])

    print("\n--- ìµœì¢… í‰ê°€ ê²°ê³¼ ---")
    if labels.size > 0:
        fpr, tpr, thresholds = roc_curve(labels, scores)
        roc_auc = auc(fpr, tpr)
        
        frr = 1 - tpr
        eer_index = np.nanargmin(np.abs(fpr - frr))
        eer = fpr[eer_index]
        eer_threshold = thresholds[eer_index]

        tar_at_far_results = {far: np.interp(far, fpr, tpr) for far in args.target_fars}
        
        predictions = (scores >= eer_threshold).astype(int)
        cm = confusion_matrix(labels, predictions)
        
        tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0,0,0,0)

        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        metrics = {"accuracy": accuracy, "recall": recall, "f1_score": f1_score, "tp": tp, "tn": tn, "fp": fp, "fn": fn}

        print(f"ì „ì²´ í‰ê°€ ìŒ: {len(labels)} ê°œ")
        print(f"[ì£¼ìš” ì„±ëŠ¥] ROC-AUC: {roc_auc:.4f}, EER: {eer:.4f} (ìœ ì‚¬ë„ ì„ê³„ê°’: {eer_threshold:.4f})")
        print(f"[ìƒì„¸ ì§€í‘œ] Accuracy: {metrics['accuracy']:.4f}, Recall: {metrics['recall']:.4f}, F1-Score: {metrics['f1_score']:.4f}")
        for far, tar in tar_at_far_results.items():
            print(f"  - TAR @ FAR {far*100:g}%: {tar:.4f}")
        
        with open(LOG_FILE, 'a') as log_file:
            log_file.write(f"\ní‰ê°€ ê²°ê³¼:\n")
            log_file.write(f"ROC-AUC: {roc_auc:.4f}, EER: {eer:.4f} (Threshold: {eer_threshold:.4f})\n")
            log_file.write(f"Accuracy: {metrics['accuracy']:.4f}, Recall: {metrics['recall']:.4f}, F1-Score: {metrics['f1_score']:.4f}\n")
            for far, tar in tar_at_far_results.items():
                log_file.write(f"TAR @ FAR {far*100:g}%: {tar:.4f}\n")
            log_file.write("\n")  # ë¹ˆ ì¤„ ì¶”ê°€

        excel_path = os.path.join(script_dir, args.excel_path)
        total_dataset_img_len = sum(len(v) for v in identity_map.values())
        total_class = len(identity_map)
        
        # Calculate identification metrics
        rank_1_accuracy, rank_5_accuracy, cmc_curve, max_rank, total_probes = calculate_identification_metrics(identity_map, embeddings)

        if rank_1_accuracy is not None:
            print(f"\n--- ì–¼êµ´ ì‹ë³„ ì„±ëŠ¥ ---")
            print(f"Rank-1 Accuracy: {rank_1_accuracy:.4f}")
            print(f"Rank-5 Accuracy: {rank_5_accuracy:.4f}")
            print(f"ì´ í”„ë¡œë¸Œ ì´ë¯¸ì§€ ìˆ˜: {total_probes}")

            with open(LOG_FILE, 'a') as log_file:
                log_file.write(f"\nì–¼êµ´ ì‹ë³„ ì„±ëŠ¥:\n")
                log_file.write(f"Rank-1 Accuracy: {rank_1_accuracy:.4f}\n")
                log_file.write(f"Rank-5 Accuracy: {rank_5_accuracy:.4f}\n")
                log_file.write(f"ì´ í”„ë¡œë¸Œ ì´ë¯¸ì§€ ìˆ˜: {total_probes}\n")
                if cmc_curve is not None:
                    log_file.write(f"CMC Curve (first 10 ranks): {cmc_curve[:10].tolist()}\n")
                log_file.write("\n")

            # Plot CMC Curve
            if cmc_curve is not None and max_rank > 0:
                plt.figure(figsize=(8, 6))
                plt.plot(np.arange(1, max_rank + 1), cmc_curve, marker='o', linestyle='-', markersize=4)
                plt.xlim([1, min(max_rank, 20)]) # Show up to rank 20 or max_rank
                plt.ylim([0.0, 1.05])
                plt.xlabel('Rank (k)')
                plt.ylabel('Accuracy')
                plt.title(f'CMC Curve for {args.model}')
                plt.grid(True)
                cmc_plot_filename = os.path.splitext(excel_path)[0] + f"_{args.model}_cmc_curve.png"
                plt.savefig(cmc_plot_filename)
                print(f"CMC ì»¤ë¸Œ ê·¸ë˜í”„ê°€ '{cmc_plot_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("\n--- ì–¼êµ´ ì‹ë³„ ì„±ëŠ¥ ---")
            print("ì–¼êµ´ ì‹ë³„ ì„±ëŠ¥ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ìœ íš¨í•œ í”„ë¡œë¸Œ ì´ë¯¸ì§€ ë¶€ì¡±).")
            with open("LOG_FILE", 'a') as log_file:
                log_file.write("\nì–¼êµ´ ì‹ë³„ ì„±ëŠ¥:\n")
                log_file.write("ì–¼êµ´ ì‹ë³„ ì„±ëŠ¥ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ìœ íš¨í•œ í”„ë¡œë¸Œ ì´ë¯¸ì§€ ë¶€ì¡±).\n")
                log_file.write("\n")

        save_results_to_excel(excel_path, args.model, roc_auc, eer, tar_at_far_results, \
                              args.target_fars, metrics, total_dataset_img_len, total_class, args.data_path, args.model,
                              rank_1_accuracy, rank_5_accuracy)

        plot_roc_curve(fpr, tpr, roc_auc, args.model, excel_path)
    else:
        msg = "í‰ê°€ë¥¼ ìœ„í•œ ìœ íš¨í•œ ì ìˆ˜ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        print(msg)
        logging.error(msg)

def save_results_to_excel(excel_path, model_name, roc_auc, eer, tar_at_far_results, target_fars, metrics, total_dataset_img_len, total_class,
                           data_path, model_attr_value, rank_1_accuracy=None, rank_5_accuracy=None):
    """ê²°ê³¼ë¥¼ Excel íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    new_data = {
        "model_name": [model_name],
        "roc_auc": [f"{roc_auc:.4f}"], "eer": [f"{eer:.4f}"],
        "accuracy": [f"{metrics['accuracy']:.4f}"], "recall": [f"{metrics['recall']:.4f}"],
        "f1_score": [f"{metrics['f1_score']:.4f}"], "tp": [metrics['tp']],
        "tn": [metrics['tn']], "fp": [metrics['fp']], "fn": [metrics['fn']]
    }

    for far in target_fars:
        new_data[f"tar_at_far_{far*100:g}%"] = [f"{tar_at_far_results.get(far, 0):.4f}"]

    if rank_1_accuracy is not None:
        new_data["rank_1_accuracy"] = [f"{rank_1_accuracy:.4f}"]
    if rank_5_accuracy is not None:
        new_data["rank_5_accuracy"] = [f"{rank_5_accuracy:.4f}"]

    new_data.update({
        'total_dataset_img_len': [total_dataset_img_len],
        'total_class': [total_class],
        'data_path': [data_path],
        'model_attr': [model_attr_value]
    })
    
    new_df = pd.DataFrame(new_data)
    try:
        df = pd.read_excel(excel_path)
    except FileNotFoundError:
        df = pd.DataFrame()

    updated_df = pd.concat([df, new_df], ignore_index=True)
    updated_df.to_excel(excel_path, index=False)
    print(f"\ní‰ê°€ ê²°ê³¼ê°€ '{excel_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def plot_roc_curve(fpr, tpr, roc_auc, model_name, excel_path):
    """ROC ì»¤ë¸Œë¥¼ ê·¸ë¦¬ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate (FAR)')
    plt.ylabel('True Positive Rate (TAR)')
    plt.title(f'ROC Curve {model_name}')
    plt.legend(loc="lower right")
    plt.grid(True)
    plot_filename = os.path.splitext(excel_path)[0] + f"_{model_name}_roc_curve.png"
    plt.savefig(plot_filename)
    print(f"ROC ì»¤ë¸Œ ê·¸ë˜í”„ê°€ '{plot_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="SEvaluation Script")
    parser.add_argument('--model',type=str , default='Glint360K_R50_TopoFR_9727', choices=['Glint360K_R50_TopoFR_9727, Glint360K_R200_TopoFR', 'MS1MV2_R200_TopoFR', 'Glint360K_R100_TopoFR_9760'],)
    parser.add_argument("--data_path", type=str, default="/home/ubuntu/KOR_DATA/ì¼ë°˜/kor_data_sorting", help="í‰ê°€í•  ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ í´ë”")
    parser.add_argument("--excel_path", type=str, default="evaluation_results.xlsx", help="ê²°ê³¼ë¥¼ ì €ì¥í•  Excel íŒŒì¼ ì´ë¦„")
    parser.add_argument("--target_fars", nargs='+', type=float, default=[0.01, 0.001, 0.0001], help="TARì„ ê³„ì‚°í•  FAR ëª©í‘œê°’ë“¤")
    parser.add_argument("--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu", help="ì‚¬ìš©í•  ì¥ì¹˜ (ì˜ˆ: cpu, cuda, cuda:0)")
    parser.add_argument("--batch_size", type=int, default=512, help="ì„ë² ë”© ì¶”ì¶œ ì‹œ ë°°ì¹˜ í¬ê¸°")
    parser.add_argument('--load_cache' , type=str , default = None ,help="ì„ë² ë”© ìºì‹œê²½ë¡œ")
    args = parser.parse_args()

    for key , values in args.__dict__.items():
        print(f"key {key}  :  {values}")

    main(args)