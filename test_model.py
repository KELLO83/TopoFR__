import os
import glob
import cv2
import itertools
from natsort import natsorted
import torch
import numpy as np
import matplotlib.pyplot as plt
import torchvision.transforms.v2 as v2

representative_image = cv2.imread('frr_detected/0.jpg')
# file_list = glob.glob('19082031/*.jpg')
# file_list = natsorted(file_list)
# representative_image = cv2.imread(file_list[0])
# far_list = glob.glob('far_detected/*.jpg')  # ë‹¤ë¥¸ ì¸ë¬¼ (Negative samples)
# frr_list = glob.glob('frr_detected/*.jpg')  # ê°™ì€ ì¸ë¬¼ (Positive samples)


far_list = glob.glob('far_seg_aligend/*.jpg')  # ë‹¤ë¥¸ ì¸ë¬¼ (Negative samples)
frr_list = glob.glob('frr_seg_aligend/*.jpg')  # ê°™ì€ ì¸ë¬¼ (Positive samples)


far_list = natsorted(far_list)
frr_list = natsorted(frr_list)

print(f"FAR ì´ë¯¸ì§€ ìˆ˜: {len(far_list)} (ë‹¤ë¥¸ ì¸ë¬¼)")
print(f"FRR ì´ë¯¸ì§€ ìˆ˜: {len(frr_list)} (ê°™ì€ ì¸ë¬¼)")
print(f"ì´ í‰ê°€ ì´ë¯¸ì§€ ìˆ˜: {len(far_list) + len(frr_list)}")



from backbones.iresnet import IResNet , IBasicBlock
Weight_path = 'Glint360K_R200_TopoFR_9784.pt'
backbone = IResNet(IBasicBlock, [6, 26, 60, 6] , num_classes=360232)
# Weight_path = 'Glint360K_R100_TopoFR_9760.pt'
# backbone = IResNet(IBasicBlock, [3, 13, 30, 3] , num_classes=360232)
load_result = backbone.load_state_dict(torch.load(Weight_path, map_location='cpu'), strict=False)

backbone.eval()
backbone = backbone.to('cuda')
print("ëˆ„ë½ëœ ê°€ì¤‘ì¹˜ : {}".format(load_result.missing_keys))
print("ì˜ˆìƒì¹˜ëª»í•œ ê°€ì¤‘ì¹˜ : {}".format(load_result.unexpected_keys))

if not load_result.missing_keys and not load_result.unexpected_keys:
    print("ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

from sklearn.metrics import roc_curve, auc, confusion_matrix

transforms_v2 = v2.Compose([
    v2.ToImage(), # cv2 HWC ---> Tensor C H W
    v2.Lambda(lambda x: x.flip(dims=(0,))),
    v2.ToDtype(torch.float32, scale=True),
    v2.CenterCrop(size=(112, 112)),
    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
])

if representative_image.shape[0] != 112 or representative_image.shape[1] != 112:
    representative_image_resized = cv2.resize(representative_image, (112, 112), 
                                            interpolation=cv2.INTER_CUBIC if representative_image.shape[0] > 112 else cv2.INTER_AREA)
else:
    representative_image_resized = representative_image.copy()


representative_image_tensor = transforms_v2(representative_image_resized)
representative_image_vector = representative_image_tensor.unsqueeze(0).to('cuda')
representative_image_vector = backbone(representative_image_vector)


# LayerCAMê³¼ SmoothGradCAMppë¥¼ í™œìš©í•œ íŠ¹ì§•ë§µ ì‹œê°í™”
from torchcam.methods import LayerCAM, SmoothGradCAMpp

cv2.namedWindow("LayerCAM", cv2.WINDOW_NORMAL)
cv2.namedWindow("SmoothGradCAMpp", cv2.WINDOW_NORMAL)
# --- 1. LayerCAM ì‹¤í–‰ ---
print("\n=== LayerCAM íŠ¹ì§•ë§µ ìƒì„± (Jet Colormap) ===")
# 1a. CAM ì¶”ì¶œê¸° ë° ë°ì´í„° ì¤€ë¹„
cam_extractor_layercam = LayerCAM(backbone, target_layer=backbone.bn2)
out_layercam = backbone(representative_image_tensor.unsqueeze(0).to('cuda'))
activation_map_layercam = cam_extractor_layercam(out_layercam.squeeze(0).argmax().item(), out_layercam)

# 1b. Activation map ì •ì œ ë° ì‹œê°í™”
raw_map_layercam = activation_map_layercam[0].cpu().numpy().squeeze()
raw_map_layercam = np.nan_to_num(raw_map_layercam).astype(np.float32)
resized_map_layercam = cv2.resize(raw_map_layercam, (representative_image_resized.shape[1], representative_image_resized.shape[0]))
heatmap_layercam = cv2.normalize(resized_map_layercam, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
colored_heatmap_layercam = cv2.applyColorMap(heatmap_layercam, cv2.COLORMAP_JET)
overlayed_image_layercam = cv2.addWeighted(representative_image_resized, 0.6, colored_heatmap_layercam, 0.4, 0)

cv2.imshow("LayerCAM", overlayed_image_layercam)

# --- 2. SmoothGradCAMpp ì‹¤í–‰ ---
print("\n=== SmoothGradCAMpp íŠ¹ì§•ë§µ ìƒì„± ===")
# 2a. CAM ì¶”ì¶œê¸° ì´ˆê¸°í™” (with êµ¬ë¬¸ ì‚¬ìš©)
with SmoothGradCAMpp(backbone, target_layer=backbone.bn2) as cam_extractor_sgcam:
    # 2b. CAM ìƒì„±
    out_sgcam = backbone(representative_image_tensor.unsqueeze(0).to('cuda'))
    activation_map_sgcam = cam_extractor_sgcam(out_sgcam.squeeze(0).argmax().item(), out_sgcam)

    # 2c. Activation map ì •ì œ ë° ì‹œê°í™”
    raw_map_sgcam = activation_map_sgcam[0].cpu().numpy().squeeze()
    raw_map_sgcam = np.nan_to_num(raw_map_sgcam).astype(np.float32)
    resized_map_sgcam = cv2.resize(raw_map_sgcam, (representative_image_resized.shape[1], representative_image_resized.shape[0]))
    heatmap_sgcam = cv2.normalize(resized_map_sgcam, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
    colored_heatmap_sgcam = cv2.applyColorMap(heatmap_sgcam, cv2.COLORMAP_JET)
    overlayed_image_sgcam = cv2.addWeighted(representative_image_resized, 0.6, colored_heatmap_sgcam, 0.4, 0)

    cv2.imshow("SmoothGradCAMpp", overlayed_image_sgcam)

cv2.waitKey(0)



all_similarities = []

all_labels = []
from torchcam.methods import LayerCAM

print("\n=== FRR ì´ë¯¸ì§€ ì²˜ë¦¬ (ê°™ì€ ì¸ë¬¼) ===")
for i, frr_img_path in enumerate(frr_list):
    if i == 0:  # representative ì´ë¯¸ì§€ëŠ” ì œì™¸
        continue
        
    image = cv2.imread(frr_img_path)
    
    if image.shape[0] != 112 or image.shape[1] != 112:
        image = cv2.resize(image, (112, 112), 
                          interpolation=cv2.INTER_CUBIC if image.shape[0] > 112 else cv2.INTER_AREA)


    image_tensor = transforms_v2(image)  
    image_tensor = image_tensor.unsqueeze(0).to('cuda')

    with torch.no_grad():
        output = backbone(image_tensor)
        if isinstance(output , tuple):
            _ , vectors  = output
        else:
            vectors = output

    cos_similarity = torch.nn.functional.cosine_similarity(representative_image_vector, vectors, dim=1)
    cos_similarity = cos_similarity.detach().cpu().numpy()[0]
    
    all_similarities.append(cos_similarity)
    all_labels.append(1)  # Positive sample
    
    print(f"FRR {i}: {frr_img_path} -> Similarity: {cos_similarity:.4f}")

print("\n=== FAR ì´ë¯¸ì§€ ì²˜ë¦¬ (ë‹¤ë¥¸ ì¸ë¬¼) ===")
for i, far_img_path in enumerate(far_list):
    image = cv2.imread(far_img_path)
    

    if image.shape[0] != 112 or image.shape[1] != 112:
        image = cv2.resize(image, (112, 112), 
                          interpolation=cv2.INTER_CUBIC if image.shape[0] > 112 else cv2.INTER_AREA)
    

    image_tensor = transforms_v2(image) 
    image_tensor = image_tensor.unsqueeze(0).to('cuda')

    with torch.no_grad():
        output = backbone(image_tensor)
        if isinstance(output , tuple):
            _ , vectors  = output
        else:
            vectors = output

    cos_similarity = torch.nn.functional.cosine_similarity(representative_image_vector, vectors, dim=1)
    cos_similarity = cos_similarity.detach().cpu().numpy()[0]
    
    all_similarities.append(cos_similarity)
    all_labels.append(0)  
    print(f"FAR {i}: {far_img_path} -> Similarity: {cos_similarity:.4f}")


print("\n=== ì„±ëŠ¥ í‰ê°€ ===")
similarities_np = np.array(all_similarities)
labels_np = np.array(all_labels)
pos_similarities = similarities_np[labels_np == 1]
neg_similarities = similarities_np[labels_np == 0]

print(f"ì´ í‰ê°€ ìŒ: {len(similarities_np)}ê°œ")
print(f"Positive ìŒ (ê°™ì€ ì¸ë¬¼): {len(pos_similarities)}ê°œ")
print(f"Negative ìŒ (ë‹¤ë¥¸ ì¸ë¬¼): {len(neg_similarities)}ê°œ")

if len(similarities_np) > 0:
    fpr, tpr, thresholds = roc_curve(labels_np, similarities_np)
    roc_auc = auc(fpr, tpr)
    
    frr = 1 - tpr  
    eer_index = np.nanargmin(np.abs(fpr - frr))
    eer = fpr[eer_index]
    eer_threshold = thresholds[eer_index]
    
    predictions = (similarities_np >= eer_threshold).astype(int)
    cm = confusion_matrix(labels_np, predictions)
    
    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)

    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Accept Rate
    frr_rate = fn / (fn + tp) if (fn + tp) > 0 else 0  # False Reject Rate
    
    print("\n--- ğŸ“Š ìµœì¢… ì„±ëŠ¥ ê²°ê³¼ ---")
    print(f"ğŸ¯ ROC-AUC: {roc_auc:.4f}")
    print(f"ğŸ¯ EER: {eer:.4f} (ì„ê³„ê°’: {eer_threshold:.4f})")
    print(f"ğŸ“ˆ Accuracy: {accuracy:.4f}")
    print(f"ğŸ“ˆ Precision: {precision:.4f}")
    print(f"ğŸ“ˆ Recall (TPR): {recall:.4f}")
    print(f"ğŸ“ˆ Specificity (TNR): {specificity:.4f}")
    print(f"ğŸ“ˆ F1-Score: {f1_score:.4f}")
    print(f"ğŸ“ˆ FAR (False Accept Rate): {far:.4f}")
    print(f"ğŸ“ˆ FRR (False Reject Rate): {frr_rate:.4f}")
    
    print("\n--- ğŸ”¢ Confusion Matrix ---")
    print(f"True Positive (TP): {tp} (ê°™ì€ ì¸ë¬¼ì„ ê°™ì€ ì¸ë¬¼ë¡œ ì¸ì‹)")
    print(f"True Negative (TN): {tn} (ë‹¤ë¥¸ ì¸ë¬¼ì„ ë‹¤ë¥¸ ì¸ë¬¼ë¡œ ì¸ì‹)")
    print(f"False Positive (FP): {fp} (ë‹¤ë¥¸ ì¸ë¬¼ì„ ê°™ì€ ì¸ë¬¼ë¡œ ì˜¤ì¸ì‹)")
    print(f"False Negative (FN): {fn} (ê°™ì€ ì¸ë¬¼ì„ ë‹¤ë¥¸ ì¸ë¬¼ë¡œ ì˜¤ì¸ì‹)")




    # --- ìœ ì‚¬ë„ ë¶„í¬ ìƒì„¸ ë¶„ì„ ---
    print("\n--- ìœ ì‚¬ë„ ë¶„í¬ ìƒì„¸ ë¶„ì„ ---")

    # ë™ì¼ ì¸ë¬¼ (Positive) ìŒ í†µê³„
    if len(pos_similarities) > 0:
        pos_min = np.min(pos_similarities)
        pos_p10 = np.percentile(pos_similarities, 10)
        pos_median = np.median(pos_similarities)
        pos_p90 = np.percentile(pos_similarities, 90)
        pos_max = np.max(pos_similarities)
        pos_mean = np.mean(pos_similarities.astype(np.float64))
        pos_std = np.std(pos_similarities.astype(np.float64)) if len(pos_similarities) > 1 else float('nan')
        
        print(f"ğŸ”µ ë™ì¼ ì¸ë¬¼ ìŒ ìœ ì‚¬ë„ (ì´ {len(pos_similarities):,}ê°œ):")
        print(f"   - ìµœì†Œê°’: {pos_min:.4f}")
        print(f"   - 10% ë¶„ìœ„: {pos_p10:.4f}")
        print(f"   - ì¤‘ì•™ê°’ (Median): {pos_median:.4f}")
        print(f"   - 90% ë¶„ìœ„: {pos_p90:.4f}")
        print(f"   - ìµœëŒ€ê°’: {pos_max:.4f}")
        print(f"   - í‰ê· ê°’: {pos_mean:.4f}")
        print(f"   - í‘œì¤€í¸ì°¨: {pos_std:.4f}" if not np.isnan(pos_std) else "N/A")
    else:
        print("ğŸ”µ ë™ì¼ ì¸ë¬¼ ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ë‹¤ë¥¸ ì¸ë¬¼ (Negative) ìŒ í†µê³„
    if len(neg_similarities) > 0:
        neg_min = np.min(neg_similarities)
        neg_p10 = np.percentile(neg_similarities, 10)
        neg_median = np.median(neg_similarities)
        neg_p90 = np.percentile(neg_similarities, 90)
        neg_max = np.max(neg_similarities)
        neg_mean = np.mean(neg_similarities.astype(np.float64))
        neg_std = np.std(neg_similarities.astype(np.float64)) if len(neg_similarities) > 1 else float('nan')

        print(f"\nğŸ”´ ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ìœ ì‚¬ë„ (ì´ {len(neg_similarities):,}ê°œ):")
        print(f"   - ìµœì†Œê°’: {neg_min:.4f}")
        print(f"   - 10% ë¶„ìœ„: {neg_p10:.4f}")
        print(f"   - ì¤‘ì•™ê°’ (Median): {neg_median:.4f}")
        print(f"   - 90% ë¶„ìœ„: {neg_p90:.4f}")
        print(f"   - ìµœëŒ€ê°’: {neg_max:.4f}")
        print(f"   - í‰ê· ê°’: {neg_mean:.4f}")
        print(f"   - í‘œì¤€í¸ì°¨: {neg_std:.4f}" if not np.isnan(neg_std) else "N/A")
    else:
        print("\nğŸ”´ ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


    with open("similarity_test_elfin", "w") as f:
        f.write(f"True Positive (TP): {tp} (ê°™ì€ ì¸ë¬¼ì„ ê°™ì€ ì¸ë¬¼ë¡œ ì¸ì‹)\n")
        f.write(f"True Negative (TN): {tn} (ë‹¤ë¥¸ ì¸ë¬¼ì„ ë‹¤ë¥¸ ì¸ë¬¼ë¡œ ì¸ì‹)\n")
        f.write(f"False Positive (FP): {fp} (ë‹¤ë¥¸ ì¸ë¬¼ì„ ê°™ì€ ì¸ë¬¼ë¡œ ì˜¤ì¸ì‹)\n")
        f.write(f"False Negative (FN): {fn} (ê°™ì€ ì¸ë¬¼ì„ ë‹¤ë¥¸ ì¸ë¬¼ë¡œ ì˜¤ì¸ì‹)\n")
        f.write(f"\n--- ğŸ“Š ìµœì¢… ì„±ëŠ¥ ê²°ê³¼ ---\n")
        f.write(f"ğŸ¯ ROC-AUC: {roc_auc:.4f}\n")
        f.write(f"ğŸ¯ EER: {eer:.4f} (ì„ê³„ê°’: {eer_threshold:.4f})\n")
        f.write(f"ğŸ“ˆ Accuracy: {accuracy:.4f}\n")
        f.write(f"ğŸ“ˆ Precision: {precision:.4f}\n")
        f.write(f"ğŸ“ˆ Recall (TPR): {recall:.4f}\n")
        f.write(f"ğŸ“ˆ Specificity (TNR): {specificity:.4f}\n")
        f.write(f"ğŸ“ˆ F1-Score: {f1_score:.4f}\n")
        f.write(f"ğŸ“ˆ FAR (False Accept Rate): {far:.4f}\n")
        f.write(f"ğŸ“ˆ FRR (False Reject Rate): {frr_rate:.4f}\n")

        # --- ìœ ì‚¬ë„ ë¶„í¬ ìƒì„¸ ë¶„ì„ ---
        f.write("\n--- ìœ ì‚¬ë„ ë¶„í¬ ìƒì„¸ ë¶„ì„ ---\n")

        # ë™ì¼ ì¸ë¬¼ (Positive) ìŒ í†µê³„
        if len(pos_similarities) > 0:
            f.write(f"ğŸ”µ ë™ì¼ ì¸ë¬¼ ìŒ ìœ ì‚¬ë„ (ì´ {len(pos_similarities):,}ê°œ):\n")
            f.write(f"   - ìµœì†Œê°’: {pos_min:.4f}\n")
            f.write(f"   - 10% ë¶„ìœ„: {pos_p10:.4f}\n")
            f.write(f"   - ì¤‘ì•™ê°’ (Median): {pos_median:.4f}\n")
            f.write(f"   - 90% ë¶„ìœ„: {pos_p90:.4f}\n")
            f.write(f"   - ìµœëŒ€ê°’: {pos_max:.4f}\n")
            f.write(f"   - í‰ê· ê°’: {pos_mean:.4f}\n")
            f.write(f"   - í‘œì¤€í¸ì°¨: {pos_std:.4f}\n")
        else:
            f.write("ğŸ”µ ë™ì¼ ì¸ë¬¼ ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n")

        # ë‹¤ë¥¸ ì¸ë¬¼ (Negative) ìŒ í†µê³„
        if len(neg_similarities) > 0:
            f.write("\n")
            f.write(f"\nğŸ”´ ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ìœ ì‚¬ë„ (ì´ {len(neg_similarities):,}ê°œ):\n")
            f.write(f"   - ìµœì†Œê°’: {neg_min:.4f}\n")
            f.write(f"   - 10% ë¶„ìœ„: {neg_p10:.4f}\n")
            f.write(f"   - ì¤‘ì•™ê°’ (Median): {neg_median:.4f}\n")
            f.write(f"   - 90% ë¶„ìœ„: {neg_p90:.4f}\n")
            f.write(f"   - ìµœëŒ€ê°’: {neg_max:.4f}\n")
            f.write(f"   - í‰ê· ê°’: {neg_mean:.4f}\n")
            f.write(f"   - í‘œì¤€í¸ì°¨: {neg_std:.4f}\n")
        else:
            f.write("\nğŸ”´ ë‹¤ë¥¸ ì¸ë¬¼ ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n")


    plt.figure(figsize=(15, 5))

    # 1. ROC ì»¤ë¸Œ
    plt.subplot(1, 3, 1)
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.scatter(fpr[eer_index], tpr[eer_index], color='red', s=100, zorder=5, label=f'EER = {eer:.4f}')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate (FAR)')
    plt.ylabel('True Positive Rate (TPR)')
    plt.title('ROC Curve')
    plt.legend(loc="lower right")
    plt.grid(True)

    plt.subplot(1, 3, 2)
    positive_similarities = similarities_np[labels_np == 1]
    negative_similarities = similarities_np[labels_np == 0]
    
    plt.hist(positive_similarities, bins=30, alpha=0.7, color='green', label=f'Same Person (n={len(positive_similarities)})', density=True)
    plt.hist(negative_similarities, bins=30, alpha=0.7, color='red', label=f'Different Person (n={len(negative_similarities)})', density=True)
    plt.axvline(eer_threshold, color='black', linestyle='--', linewidth=2, label=f'EER Threshold: {eer_threshold:.3f}')
    plt.xlabel('Cosine Similarity')
    plt.ylabel('Density')
    plt.title('Similarity Distribution')
    plt.legend()
    plt.grid(True)
    
    # 3. Confusion Matrix íˆíŠ¸ë§µ
    plt.subplot(1, 3, 3)
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    im = plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Normalized Confusion Matrix')
    plt.colorbar(im)
    
    classes = ['Different Person', 'Same Person']
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    
    # í…ìŠ¤íŠ¸ ì¶”ê°€
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, f'{cm[i, j]}\n({cm_normalized[i, j]:.2%})',
                ha="center", va="center", color="white" if cm_normalized[i, j] > 0.5 else "black")
    
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()

    plot_filename = "face_recognition_evaluation.png"
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    print(f"\nğŸ“Š í‰ê°€ ê²°ê³¼ ê·¸ë˜í”„ê°€ '{plot_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    plt.show()

else:
    print("âš ï¸ í‰ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
